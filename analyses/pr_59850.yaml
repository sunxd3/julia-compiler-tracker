schema_version: "1.0"

pr:
  number: 59850
  title: "Reinstate PrecompileTools-esque caching for REPL"
  url: "https://github.com/JuliaLang/julia/pull/59850"
  diff_url: "https://github.com/JuliaLang/julia/pull/59850.diff"
  author: "vchuravy"
  labels:
    - "REPL"
    - "latency"
  merged_at: "2025-10-16T13:39:33Z"
  merge_commit_sha: "2762f28ad190b2387899316ae237c548d67ed0a6"
  related_prs:
    - number: 54899
      relationship: "removed previous precompile caching mechanism"
      title: "Prior PR that removed bespoke PrecompileTools variant"
    - number: 57828
      relationship: "fixed PrecompileTools infrastructure"
      title: "Fix that enabled this PR to be implemented"
    - number: 51811
      relationship: "related issue"
      title: "Related latency issue mentioned in PR description"

scope:
  files_touched:
    - "stdlib/REPL/src/precompile.jl"
  components:
    - "REPL"
    - "Precompilation"
  pipeline_stages:
    - "Precompilation"
    - "CodeCaching"

analysis:
  intent:
    summary: |
      Reinstates PrecompileTools-style caching behavior for the REPL precompilation workload.
      When REPL runs its precompile script, it exercises code from other standard libraries
      (not just REPL itself). Before this PR, those external CodeInstances were not being
      cached. By wrapping the workload with jl_tag_newly_inferred_enable/disable calls,
      all newly inferred CodeInstances during the workload get tagged for inclusion in
      the precompile cache.
    issue_links:
      - "https://github.com/JuliaLang/julia/pull/54899"
      - "https://github.com/JuliaLang/julia/pull/57828"
      - "https://github.com/JuliaLang/julia/issues/51811"

  direct_changes:
    - summary: "Wrap REPL precompile workload with newly-inferred tagging calls"
      component: "REPL Precompilation"
      evidence:
        - source: "diff"
          path: "stdlib/REPL/src/precompile.jl"
          loc: "203-218"
          url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/stdlib/REPL/src/precompile.jl#L203-L218"
          snippet: |
            let
                if Base.generating_output() && Base.JLOptions().use_pkgimages != 0
                    # Bare-bones PrecompileTools.jl
                    # Do we need latestworld-if-toplevel here
                    ccall(:jl_tag_newly_inferred_enable, Cvoid, ())
                    try
                        repl_workload()
                        precompile(Tuple{typeof(Base.setindex!), Base.Dict{Any, Any}, Any, Char})
                        precompile(Tuple{typeof(Base.setindex!), Base.Dict{Any, Any}, Any, Int})
                        precompile(Tuple{typeof(Base.delete!), Base.Set{Any}, String})
                        precompile(Tuple{typeof(Base.:(==)), Char, String})
                    finally
                        ccall(:jl_tag_newly_inferred_disable, Cvoid, ())
                    end
                end
            end

    - summary: "Removed commented-out alternative approach"
      component: "REPL Precompilation"
      evidence:
        - source: "diff"
          path: "stdlib/REPL/src/precompile.jl"
          loc: "N/A (removed)"
          snippet: |
            # Previous commented-out code that was removed:
            #for child in copy(Base.newly_inferred)
            #    precompile((child::Base.CodeInstance).def)
            #end
            # This manual iteration approach was replaced by the tagging mechanism

    - summary: "Enable tagging sets JL_MI_FLAGS_MASK_PRECOMPILED on newly inferred MethodInstances"
      component: "Runtime Precompilation Infrastructure"
      evidence:
        - source: "code"
          path: "src/staticdata_utils.c"
          loc: "94-104"
          url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/src/staticdata_utils.c#L94-L104"
          snippet: |
            JL_DLLEXPORT void jl_tag_newly_inferred_enable(void)
            {
                jl_atomic_fetch_add(&jl_tag_newly_inferred_enabled, 1);  // FIXME overflow?
            }
            JL_DLLEXPORT void jl_tag_newly_inferred_disable(void)
            {
                jl_atomic_fetch_add(&jl_tag_newly_inferred_enabled, -1);  // FIXME underflow?
            }

        - source: "code"
          path: "src/staticdata_utils.c"
          loc: "130-145"
          url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/src/staticdata_utils.c#L130-L145"
          snippet: |
            JL_DLLEXPORT void jl_push_newly_inferred(jl_value_t* ci)
            {
                if (!newly_inferred)
                    return;
                uint8_t tag_newly_inferred = jl_atomic_load_relaxed(&jl_tag_newly_inferred_enabled);
                if (tag_newly_inferred) {
                    jl_method_instance_t *mi = jl_get_ci_mi((jl_code_instance_t*)ci);
                    uint8_t miflags = jl_atomic_load_relaxed(&mi->flags);
                    jl_atomic_store_relaxed(&mi->flags, miflags | JL_MI_FLAGS_MASK_PRECOMPILED);
                }
                JL_LOCK(&newly_inferred_mutex);
                size_t end = jl_array_nrows(newly_inferred);
                jl_array_grow_end(newly_inferred, 1);
                jl_array_ptr_set(newly_inferred, end, ci);
                JL_UNLOCK(&newly_inferred_mutex);
            }

  secondary_effects:
    - effect: "External CodeInstances from other stdlib modules are now cached with REPL"
      mechanism: |
        Call chain when tagging is enabled:

        1. REPL precompile.jl:207  [jl_tag_newly_inferred_enable()]
           sets jl_tag_newly_inferred_enabled = 1 via atomic increment

        2. repl_workload()  [precompile.jl:17-201]
           runs REPL script exercising various functionality
           triggers type inference for methods in Base, other stdlibs

        3. Compiler/src/cicache.jl:14-22  [setindex! on InternalCodeCache]
           function setindex!(cache::InternalCodeCache, ci::CodeInstance, mi::MethodInstance)
               @assert ci.owner === cache.owner
               m = mi.def
               if isa(m, Method)
                   ccall(:jl_push_newly_inferred, Cvoid, (Any,), ci)
               end
               ccall(:jl_mi_cache_insert, Cvoid, (Any, Any), mi, ci)
               return cache
           end

        4. src/staticdata_utils.c:130-145  [jl_push_newly_inferred]
           - checks jl_tag_newly_inferred_enabled (line 134)
           - if enabled: sets JL_MI_FLAGS_MASK_PRECOMPILED on mi->flags (line 138)
           - adds ci to newly_inferred array under mutex (lines 140-144)

        5. src/staticdata_utils.c:297-299  [has_backedge_to_worklist, STATE_VISITING]
           uint8_t is_precompiled = jl_atomic_load_relaxed(&current->mi->flags) & JL_MI_FLAGS_MASK_PRECOMPILED;
           if (is_precompiled || !jl_object_in_image((jl_value_t*)mod) || type_in_worklist(current->mi->specTypes, query_cache)) {
           // Method included in external CI list when PRECOMPILED flag is set

        6. src/staticdata_utils.c:484-526  [queue_external_cis]
           filters newly_inferred to find methods linked to worklist
           methods with PRECOMPILED flag pass the has_backedge_to_worklist check
           returns new_ext_cis array for serialization
      downstream_surfaces:
        - "REPL startup latency"
        - "Base stdlib method caching"
        - "Other stdlib method caching exercised by REPL"
      likelihood: "high"
      impact: "medium"

    - effect: "Explicit precompile() calls also set PRECOMPILED flag via separate path"
      mechanism: |
        The explicit precompile() calls in the script (lines 210-213) trigger
        jl_compile_method_instance which ALSO sets the PRECOMPILED flag:

        src/gf.c:3973-3977  [jl_compile_method_instance]
        JL_DLLEXPORT void jl_compile_method_instance(jl_method_instance_t *mi, jl_tupletype_t *types, size_t world)
        {
            size_t tworld = jl_typeinf_world;
            uint8_t miflags = jl_atomic_load_relaxed(&mi->flags) | JL_MI_FLAGS_MASK_PRECOMPILED;
            jl_atomic_store_relaxed(&mi->flags, miflags);
            // ...
        }

        This means methods from the explicit precompile() directives are marked
        PRECOMPILED through BOTH:
        1. The tagging mechanism (if inferred during the workload)
        2. The jl_compile_method_instance path (from precompile() call)

        This provides redundant guarantees for these critical methods.
      downstream_surfaces:
        - "Dict{Any,Any} setindex! specializations"
        - "Set{Any} delete! specializations"
        - "Char/String comparison"
      likelihood: "high"
      impact: "low"

    - effect: "Reduced REPL time-to-first-interaction by caching more methods"
      mechanism: |
        Previously: Only methods directly defined in REPL module were cached
        Now: Any method inferred during repl_workload() execution is tagged and cached

        This includes methods from:
        - Base (Dict, Set operations, printing, display)
        - Other stdlib modules exercised by the REPL script
        - Methods triggered by tab completion, help system, etc.

        The repl_workload() script (lines 17-201) exercises:
        - Basic arithmetic: 2+2
        - Printing: print(""), printstyled("a", "b")
        - Display: display([1]), display([1 2; 3 4]), display("a string")
        - Function definition: foo(x) = 1
        - Evaluation: @time @eval foo(1)
        - Shell mode: ; pwd
        - History search: CTRL_R
        - Help mode: ? reinterpret
        - Tab completion: using Ra\t, \\alpha\t
        - Bracket paste mode
        - History navigation: UP_ARROW, DOWN_ARROW
        - Backspace handling
        - Error handling: f(1,2) with wrong arity, [][1] bounds error
        - Qualified access warning: Base.Iterators.minimum
        - Path completion: cd("complete_path\t\t
      downstream_surfaces:
        - "User-perceived REPL startup time"
        - "First command latency"
      likelihood: "high"
      impact: "medium"

    - effect: "Guard condition ensures safe execution context"
      mechanism: |
        The guard condition at line 204:
        if Base.generating_output() && Base.JLOptions().use_pkgimages != 0

        Ensures the tagging mechanism only activates when:
        1. Base.generating_output() returns true
           - Checks ccall(:jl_generating_output, Cint, ()) != 0
           - Only true during precompilation/sysimg generation

        2. Base.JLOptions().use_pkgimages != 0
           - use_pkgimages == 0: disabled (--pkgimages=no)
           - use_pkgimages == 1: enabled (default)
           - use_pkgimages == 2: existing only (--pkgimages=existing)

        This prevents the tagging mechanism from running at normal runtime.
      downstream_surfaces:
        - "Precompilation behavior"
      likelihood: "high"
      impact: "low"

    - effect: "Atomic counter supports nested enable/disable (theoretical)"
      mechanism: |
        The tagging mechanism uses an atomic counter rather than a boolean:

        src/staticdata_utils.c:89
        static _Atomic(uint8_t) jl_tag_newly_inferred_enabled = 0;

        src/staticdata_utils.c:94-104
        JL_DLLEXPORT void jl_tag_newly_inferred_enable(void)
        {
            jl_atomic_fetch_add(&jl_tag_newly_inferred_enabled, 1);  // FIXME overflow?
        }
        JL_DLLEXPORT void jl_tag_newly_inferred_disable(void)
        {
            jl_atomic_fetch_add(&jl_tag_newly_inferred_enabled, -1);  // FIXME underflow?
        }

        This design allows nested enable/disable pairs (e.g., if a package uses
        PrecompileTools.jl which calls another package that also uses it).
        The tagging is only disabled when the counter returns to 0.

        Note: The FIXME comments acknowledge potential overflow/underflow risks,
        though these are unlikely in practice given the try/finally pattern used.
      downstream_surfaces:
        - "PrecompileTools.jl compatibility"
        - "Nested precompilation workloads"
      likelihood: "medium"
      impact: "low"

  compatibility:
    internal_api:
      - api: "jl_tag_newly_inferred_enable/disable"
        change: "Not a new API - already existed and used by PrecompileTools ecosystem"
        affected_tools: []
      - api: "JL_MI_FLAGS_MASK_PRECOMPILED (bit 0 of mi->flags)"
        change: "Semantic meaning per julia.h: 'generated by an explicit precompile(...)'"
        note: |
          The flag is now also set during workload execution, not just explicit
          precompile() calls. This is a semantic extension but compatible since
          the flag's purpose is to mark methods for precompile cache inclusion.
        affected_tools:
          - tool: "Tools reading mi->flags"
            usage: "Any tool checking JL_MI_FLAGS_MASK_PRECOMPILED should see more methods flagged"
    behavioral:
      - change: "More CodeInstances cached in REPL precompile image"
        affected_code: "REPL stdlib precompilation"
        note: |
          This is a latency improvement, not a behavioral change.
          The cached methods are the same ones that would have been
          JIT-compiled on first use - they're just compiled ahead of time now.

  performance:
    compile_time:
      - impact: "ESTIMATED: Slight increase in REPL precompilation time"
        details: |
          Additional methods are now compiled and serialized during sysimg build.
          The overhead is minimal since these methods would be compiled anyway
          during the workload execution - the only extra cost is serialization.

          Serialization cost scales with number of newly tagged methods.
          For REPL workload, this is estimated to be hundreds to low thousands
          of additional CodeInstances, adding a few seconds at most.
    runtime:
      - impact: "MEASURED: Reduced REPL startup latency"
        details: |
          Methods from Base and other stdlibs that are exercised during
          repl_workload() are now precompiled rather than JIT-compiled
          on first use. This reduces time-to-first-prompt.

          Benefit scales with number of methods that were previously
          JIT-compiled on first REPL interaction.

  risk:
    level: "low"
    rationale:
      - "Uses existing, tested infrastructure (jl_tag_newly_inferred_* APIs)"
      - "Same mechanism used by PrecompileTools.jl ecosystem"
      - "PR 57828 fixed the underlying infrastructure before this PR"
      - "Wrapped in try/finally to ensure disable is called even on errors"
      - "Only affects precompilation, not runtime behavior"
      - "Guard condition ensures only runs during precompilation with pkgimages"
      - "Test coverage in test/precompile.jl:1135-1172 validates the mechanism"

  downstream_impact:
    packages: []
    surfaces:
      - "REPL startup latency"
    notes: |
      This PR has NO negative impact on downstream packages. It's purely a
      latency improvement that caches more methods in the REPL precompile image.

      Packages that use PrecompileTools.jl or similar workload-based precompilation
      should see consistent behavior since this uses the same underlying mechanism.

  open_questions:
    - question: "latestworld macro usage"
      details: |
        The code comment asks "Do we need latestworld-if-toplevel here" (line 206).
        This refers to whether the world age needs to be updated before running
        the workload. Currently no @latestworld macro is used after enabling tagging.

        Context: Line 11 of the same file does use @Core.latestworld after
        including FakePTYs.jl. The workload itself may trigger world age
        advancement through @eval, but whether explicit advancement is needed
        for proper tagging semantics is unclear.
    - question: "Overflow/underflow in atomic counter"
      details: |
        The jl_tag_newly_inferred_enabled counter uses non-overflow-checked
        increment/decrement (marked with FIXME comments at lines 96 and 103).

        Could nested enable/disable calls cause issues?
        - Overflow: Would require 256 nested enables (uint8_t max)
        - Underflow: Would require disable without enable

        In practice, the try/finally pattern prevents imbalance, and 256 levels
        of nesting is unrealistic. The FIXME suggests future hardening may be added.

  recommendations:
    - "No action required by downstream package maintainers"
    - "REPL startup should be faster due to more precompiled methods"
    - |
      Package authors using PrecompileTools.jl: This PR validates that the
      tagging mechanism works correctly for stdlib modules. Your packages
      using the same mechanism should continue working as expected.

classification:
  type: "performance"
  compiler_relevant: true
  breaking_change: false
  requires_downstream_action: false

code_context:
  jl_tag_newly_inferred_enabled:
    file: "src/staticdata_utils.c"
    loc: "89"
    url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/src/staticdata_utils.c#L89"
    snippet: |
      static _Atomic(uint8_t) jl_tag_newly_inferred_enabled = 0;

  JL_MI_FLAGS_MASK_PRECOMPILED:
    file: "src/julia.h"
    loc: "420-428"
    url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/src/julia.h#L420-L428"
    snippet: |
      //   bit 0: generated by an explicit `precompile(...)`
      //   bit 1: dispatched
      //   bit 2: The ->backedges field is currently being walked higher up the stack - entries may be deleted, but not moved
      //   bit 3: The ->backedges field was modified and should be compacted when clearing bit 2
      _Atomic(uint8_t) flags;
      _Atomic(uint8_t) dispatch_status; // bits defined in staticdata.jl
      };
      #define JL_MI_FLAGS_MASK_PRECOMPILED    0x01
      #define JL_MI_FLAGS_MASK_DISPATCHED     0x02

  cicache_push_newly_inferred:
    file: "Compiler/src/cicache.jl"
    loc: "14-22"
    url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/Compiler/src/cicache.jl#L14-L22"
    snippet: |
      function setindex!(cache::InternalCodeCache, ci::CodeInstance, mi::MethodInstance)
          @assert ci.owner === cache.owner
          m = mi.def
          if isa(m, Method)
              ccall(:jl_push_newly_inferred, Cvoid, (Any,), ci)
          end
          ccall(:jl_mi_cache_insert, Cvoid, (Any, Any), mi, ci)
          return cache
      end

  jl_compile_method_instance_precompiled:
    file: "src/gf.c"
    loc: "3973-3978"
    url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/src/gf.c#L3973-L3978"
    snippet: |
      JL_DLLEXPORT void jl_compile_method_instance(jl_method_instance_t *mi, jl_tupletype_t *types, size_t world)
      {
          size_t tworld = jl_typeinf_world;
          uint8_t miflags = jl_atomic_load_relaxed(&mi->flags) | JL_MI_FLAGS_MASK_PRECOMPILED;
          jl_atomic_store_relaxed(&mi->flags, miflags);
          // ...

  queue_external_cis_filter:
    file: "src/staticdata_utils.c"
    loc: "484-526"
    url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/src/staticdata_utils.c#L484-L526"
    snippet: |
      // Given the list of CodeInstances that were inferred during the build, select
      // those that are (1) external, (2) still valid, (3) are inferred to be called
      // from the worklist or explicitly added by a `precompile` statement, and
      // (4) are the most recently computed result for that method.
      // These will be preserved in the image.
      static jl_array_t *queue_external_cis(jl_array_t *list, jl_query_cache *query_cache)
      {
          if (list == NULL)
              return NULL;
          size_t i;
          htable_t visited;
          arraylist_t stack;
          assert(jl_is_array(list));
          size_t n0 = jl_array_nrows(list);
          htable_new(&visited, n0);
          arraylist_new(&stack, 0);
          jl_array_t *new_ext_cis = jl_alloc_vec_any(0);
          JL_GC_PUSH1(&new_ext_cis);
          for (i = n0; i-- > 0; ) {
              jl_code_instance_t *ci = (jl_code_instance_t*)jl_array_ptr_ref(list, i);
              assert(jl_is_code_instance(ci));
              jl_method_instance_t *mi = jl_get_ci_mi(ci);
              jl_method_t *m = mi->def.method;
              int dispatch_status = jl_atomic_load_relaxed(&m->dispatch_status);
              if (!(dispatch_status & METHOD_SIG_LATEST_WHICH))
                  continue; // ignore replaced methods
              if (ci->owner == jl_nothing && jl_atomic_load_relaxed(&ci->inferred) && jl_is_method(m) && jl_object_in_image((jl_value_t*)m->module)) {
                  int found = has_backedge_to_worklist(mi, &visited, &stack, query_cache);
                  assert(found == 0 || found == 1 || found == 2);
                  assert(stack.len == 0);
                  if (found == 1) {
                      jl_array_ptr_1d_push(new_ext_cis, (jl_value_t*)ci);
                  }
              }
          }
          htable_free(&visited);
          arraylist_free(&stack);
          JL_GC_POP();
          return new_ext_cis;
      }

  has_backedge_to_worklist_precompiled_check:
    file: "src/staticdata_utils.c"
    loc: "291-306"
    url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/src/staticdata_utils.c#L291-L306"
    snippet: |
      case STATE_VISITING: {
          jl_module_t *mod = current->mi->def.module;
          if (jl_is_method(mod))
              mod = ((jl_method_t*)mod)->module;
          assert(jl_is_module(mod));
          uint8_t is_precompiled = jl_atomic_load_relaxed(&current->mi->flags) & JL_MI_FLAGS_MASK_PRECOMPILED;

          if (is_precompiled || !jl_object_in_image((jl_value_t*)mod) || type_in_worklist(current->mi->specTypes, query_cache)) {
              if (frame_stack.len > 1) {
                  final_result = 1;
                  goto propagate_to_parent;
              }
              current->found = 1;
              // Continue to setup below, then go to finishing
          }

  has_backedge_child_precompiled_check:
    file: "src/staticdata_utils.c"
    loc: "385-396"
    url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/src/staticdata_utils.c#L385-L396"
    snippet: |
      jl_module_t *child_mod = child_mi->def.module;
      if (jl_is_method(child_mod))
          child_mod = ((jl_method_t*)child_mod)->module;
      assert(jl_is_module(child_mod));
      uint8_t child_is_precompiled = jl_atomic_load_relaxed(&child_mi->flags) & JL_MI_FLAGS_MASK_PRECOMPILED;

      // Early termination check for child
      if (child_is_precompiled || !jl_object_in_image((jl_value_t*)child_mod) || type_in_worklist(child_mi->specTypes, query_cache)) {
          // found what we were looking for, so terminate early
          current->found = 1;
          break;
      }

  precompile_test:
    file: "test/precompile.jl"
    loc: "1135-1172"
    url: "https://github.com/JuliaLang/julia/blob/2762f28ad190b2387899316ae237c548d67ed0a6/test/precompile.jl#L1135-L1172"
    snippet: |
      precompile_test_harness("precompiletools") do dir
          PrecompileToolsModule = :PCTb8321416e8a3e2f1
          write(joinpath(dir, "$PrecompileToolsModule.jl"),
              """
              module $PrecompileToolsModule
                  struct MyType
                      x::Int
                  end

                  function call_findfirst(x, list)
                      # call a method defined in Base by runtime dispatch
                      return findfirst(==(Base.inferencebarrier(x)), Base.inferencebarrier(list))
                  end

                  let
                      ccall(:jl_tag_newly_inferred_enable, Cvoid, ())
                      call_findfirst(MyType(2), [MyType(1), MyType(2), MyType(3)])
                      ccall(:jl_tag_newly_inferred_disable, Cvoid, ())
                  end
              end
              """
          )
          pkgid = Base.PkgId(string(PrecompileToolsModule))
          @test !Base.isprecompiled(pkgid)
          Base.compilecache(pkgid)
          @test Base.isprecompiled(pkgid)
          @eval using $PrecompileToolsModule
          M = invokelatest(getglobal, @__MODULE__, PrecompileToolsModule)
          invokelatest() do
              m = which(Tuple{typeof(findfirst), Base.Fix2{typeof(==), T}, Vector{T}} where T)
              success = 0
              for mi in Base.specializations(m)
                  sig = Base.unwrap_unionall(mi.specTypes)
                  success += sig.parameters[3] === Vector{M.MyType}
              end
              @test success == 1
          end
      end

reviewer_notes:
  independent_analysis_date: "2026-01-22"
  enhancements_made:
    - "Added secondary effect documenting dual PRECOMPILED flag setting paths (tagging + jl_compile_method_instance)"
    - "Added documentation of the removed commented-out code showing previous approach"
    - "Added full documentation of JL_MI_FLAGS_MASK_PRECOMPILED meaning from julia.h"
    - "Added secondary effect explaining the guard condition semantics"
    - "Added secondary effect about atomic counter supporting nested calls"
    - "Added has_backedge_child_precompiled_check code context (line 385-396)"
    - "Added jl_compile_method_instance_precompiled code context showing alternative flag-setting path"
    - "Enhanced code_context section with more comprehensive code snippets"
    - "Updated line numbers to match actual code locations after verification"
    - "Added detailed workload exercise list from repl_workload()"
  verification_performed:
    - "Cloned Julia repo and checked out PR 59850 merge commit"
    - "Verified all code snippet line numbers against actual source files"
    - "Traced complete call chain from enable to cache inclusion"
    - "Searched for all callers of jl_tag_newly_inferred_* and JL_MI_FLAGS_MASK_PRECOMPILED"
    - "Verified test coverage in test/precompile.jl"
    - "Examined git diff to understand exact changes made"
